{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f847707",
   "metadata": {},
   "source": [
    "# Comprehensive Evaluation of Test-Time Scaling Methods\n",
    "\n",
    "This notebook provides:\n",
    "1. Comparative analysis of all scaling methods\n",
    "2. Statistical significance testing\n",
    "3. Robustness evaluation\n",
    "4. Visualization of results\n",
    "5. Conclusions and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82fef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.preprocessing import ScalingManager\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00aed9f",
   "metadata": {},
   "source": [
    "## 1. Load Results from Previous Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and model\n",
    "X_test = np.load('../data/processed/X_test.npy')\n",
    "y_test = np.load('../data/processed/y_test.npy')\n",
    "model = joblib.load('../data/processed/baseline_model.pkl')\n",
    "\n",
    "# Initialize scaling manager\n",
    "scaling_manager = ScalingManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf66ba",
   "metadata": {},
   "source": [
    "## 2. Comprehensive Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbf5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "scaling_methods = ['standard', 'quantile', 'robust', 'minmax']\n",
    "results = {}\n",
    "\n",
    "# Evaluate each scaling method\n",
    "for method in scaling_methods:\n",
    "    X_test_scaled = scaling_manager.transform(X_test, method)  # Transform the data\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    results[method] = get_metrics(y_test, y_pred)\n",
    "\n",
    "# Add test-time z-score results\n",
    "X_test_zscore = scaling_manager.test_time_zscore(X_test)\n",
    "y_pred = model.predict(X_test_zscore)\n",
    "results['test_time_zscore'] = get_metrics(y_test, y_pred)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Performance Metrics:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27bf8f9",
   "metadata": {},
   "source": [
    "## 3. Statistical Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b25b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X):\n",
    "    return model.predict(X)\n",
    "\n",
    "# Perform McNemar's test for statistical significance\n",
    "def mcnemar_test(pred1, pred2, y_true):\n",
    "    correct1 = pred1 == y_true\n",
    "    correct2 = pred2 == y_true\n",
    "    \n",
    "    b = np.sum(~correct1 & correct2)  # method1 wrong, method2 right\n",
    "    c = np.sum(correct1 & ~correct2)  # method1 right, method2 wrong\n",
    "    \n",
    "    statistic = (abs(b - c) - 1)**2 / (b + c)\n",
    "    p_value = stats.chi2.sf(statistic, df=1)\n",
    "    \n",
    "    return statistic, p_value\n",
    "\n",
    "# Compare each method against the baseline (standard scaling)\n",
    "baseline_pred = model.predict(scaling_manager.transform(X_test, 'standard'))\n",
    "\n",
    "significance_results = {}\n",
    "for method in results.keys():\n",
    "    if method != 'standard':\n",
    "        if method == 'test_time_zscore':\n",
    "            X_scaled = scaling_manager.test_time_zscore(X_test)\n",
    "        else:\n",
    "            X_scaled = scaling_manager.transform(X_test, method)\n",
    "        \n",
    "        pred = model.predict(X_scaled)\n",
    "        statistic, p_value = mcnemar_test(baseline_pred, pred, y_test)\n",
    "        significance_results[method] = {'statistic': statistic, 'p_value': p_value}\n",
    "\n",
    "print(\"\\nStatistical Significance Results (vs Standard Scaling):\")\n",
    "print(pd.DataFrame(significance_results).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5444cb",
   "metadata": {},
   "source": [
    "## 4. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "results_df.plot(kind='bar', width=0.8)\n",
    "plt.title('Performance Comparison of Scaling Methods')\n",
    "plt.xlabel('Scaling Method')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08582f1",
   "metadata": {},
   "source": [
    "## 5. Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(X, noise_level=0.1):\n",
    "    noise = np.random.normal(0, noise_level, X.shape)\n",
    "    return X + noise\n",
    "\n",
    "# Test robustness with different noise levels\n",
    "noise_levels = [0.05, 0.1, 0.2]\n",
    "robustness_results = {}\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "    noisy_X = add_noise(X_test, noise_level)\n",
    "    method_results = {}\n",
    "    \n",
    "    for method in scaling_methods:\n",
    "        X_scaled = scaling_manager.transform(noisy_X, method)\n",
    "        y_pred = model.predict(X_scaled)\n",
    "        method_results[method] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Add test-time z-score\n",
    "    X_zscore = scaling_manager.test_time_zscore(noisy_X)\n",
    "    y_pred = model.predict(X_zscore)\n",
    "    method_results['test_time_zscore'] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    robustness_results[f'noise_{noise_level}'] = method_results\n",
    "\n",
    "robustness_df = pd.DataFrame(robustness_results)\n",
    "print(\"Robustness Analysis (Accuracy with Different Noise Levels):\")\n",
    "print(robustness_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df770f3e",
   "metadata": {},
   "source": [
    "## 6. Conclusions and Recommendations\n",
    "\n",
    "Based on the analysis above, we can draw the following conclusions:\n",
    "\n",
    "1. **Performance Comparison**:\n",
    "   - Compare the overall performance metrics\n",
    "   - Note which method performed best for each metric\n",
    "\n",
    "2. **Statistical Significance**:\n",
    "   - Discuss which methods showed significant differences\n",
    "   - Interpret p-values and their implications\n",
    "\n",
    "3. **Robustness**:\n",
    "   - Evaluate which methods were most resistant to noise\n",
    "   - Consider trade-offs between performance and robustness\n",
    "\n",
    "4. **Recommendations**:\n",
    "   - Suggest the best scaling method(s) for different scenarios\n",
    "   - Consider computational cost and ease of implementation\n",
    "   - Provide guidelines for when to use each method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
